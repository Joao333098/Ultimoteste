/**
 * Backend NLP Services para an√°lise avan√ßada
 * Integra com GLM-4 para an√°lise inteligente
 */

import axios from 'axios';
import { config } from '../config';

// Helper function para fazer requests para GLM-4
async function callGLM4API(prompt: string, options: {
  temperature?: number;
  max_tokens?: number;
} = {}): Promise<string> {
  try {
    console.log('üîß Fazendo chamada para GLM-4 API...');
    const response = await axios.post(
      config.ai.endpoint,
      {
        model: config.ai.model,
        messages: [{
          role: "user",
          content: prompt
        }],
        temperature: options.temperature || 0.3,
        max_tokens: options.max_tokens || 500
      },
      {
        headers: {
          'Authorization': `Bearer ${config.GLM4_API_KEY}`,
          'Content-Type': 'application/json'
        },
        timeout: 30000
      }
    );
    
    console.log('‚úÖ Resposta recebida da GLM-4 API');
    return response.data.choices[0].message.content;
  } catch (error: any) {
    console.error('‚ùå Erro na API GLM-4:', error.response?.data || error.message);
    // Retornar resposta fallback ao inv√©s de falhar
    return JSON.stringify({
      answer: "Desculpe, estou com dificuldades t√©cnicas no momento. Tente novamente em alguns segundos.",
      confidence: 0.3,
      relatedTopics: [],
      reasoning: "Erro t√©cnico na API",
      additionalInsights: [],
      contextAware: false
    });
  }
}

// Interface para resultado de an√°lise avan√ßada
export interface AdvancedAnalysisResult {
  answer: string;
  confidence: number;
  relatedTopics: string[];
  responseType: 'answer' | 'explanation' | 'clarification' | 'suggestion';
  contextAware: boolean;
  reasoning: string;
  additionalInsights: string[];
}

// An√°lise avan√ßada de sentimento com GLM-4
export async function analyzeAdvancedSentiment(text: string): Promise<{
  sentiment: 'positive' | 'negative' | 'neutral';
  intensity: number;
  confidence: number;
  emotions: {
    joy: number;
    anger: number;
    fear: number;
    sadness: number;
    surprise: number;
    disgust: number;
  };
  explanation: string;
}> {
  try {
    const prompt = `Analise o sentimento do seguinte texto de forma muito detalhada:

TEXTO: "${text}"

Fa√ßa uma an√°lise profunda incluindo:
1. Sentimento geral (positive/negative/neutral)
2. Intensidade (0-1)
3. Confian√ßa na an√°lise (0-1) 
4. Emo√ß√µes espec√≠ficas (joy, anger, fear, sadness, surprise, disgust) em escala 0-1
5. Explica√ß√£o do racioc√≠nio

Responda em formato JSON:
{
  "sentiment": "positive|negative|neutral",
  "intensity": 0.8,
  "confidence": 0.9,
  "emotions": {
    "joy": 0.7,
    "anger": 0.1,
    "fear": 0.0,
    "sadness": 0.1,
    "surprise": 0.2,
    "disgust": 0.0
  },
  "explanation": "Explica√ß√£o detalhada da an√°lise"
}`;

    const responseText = await callGLM4API(prompt, {
      temperature: 0.3,
      max_tokens: 500
    });

    try {
      const parsed = JSON.parse(responseText);
      return {
        sentiment: parsed.sentiment || 'neutral',
        intensity: Math.max(0, Math.min(1, parsed.intensity || 0.5)),
        confidence: Math.max(0, Math.min(1, parsed.confidence || 0.7)),
        emotions: {
          joy: Math.max(0, Math.min(1, parsed.emotions?.joy || 0)),
          anger: Math.max(0, Math.min(1, parsed.emotions?.anger || 0)),
          fear: Math.max(0, Math.min(1, parsed.emotions?.fear || 0)),
          sadness: Math.max(0, Math.min(1, parsed.emotions?.sadness || 0)),
          surprise: Math.max(0, Math.min(1, parsed.emotions?.surprise || 0)),
          disgust: Math.max(0, Math.min(1, parsed.emotions?.disgust || 0))
        },
        explanation: parsed.explanation || "An√°lise de sentimento conclu√≠da"
      };
    } catch (parseError) {
      console.error('Erro ao parsear resposta de sentimento:', parseError);
      return {
        sentiment: 'neutral',
        intensity: 0.5,
        confidence: 0.3,
        emotions: { joy: 0, anger: 0, fear: 0, sadness: 0, surprise: 0, disgust: 0 },
        explanation: "Erro na an√°lise - resposta padr√£o"
      };
    }
  } catch (error) {
    console.error('Erro na an√°lise de sentimento avan√ßada:', error);
    throw new Error('Falha na an√°lise de sentimento');
  }
}

// Detec√ß√£o avan√ßada de inten√ß√µes
export async function detectAdvancedIntent(text: string, context?: string[]): Promise<{
  primary: 'question' | 'command' | 'statement' | 'exclamation' | 'request';
  confidence: number;
  subtype: string;
  requiresResponse: boolean;
  priority: 'high' | 'medium' | 'low';
  reasoning: string;
  suggestedActions: string[];
}> {
  try {
    const contextInfo = context && context.length > 0 
      ? `\nCONTEXTO ANTERIOR:\n${context.slice(-3).join('\n')}`
      : '';

    const prompt = `Analise a inten√ß√£o do seguinte texto de forma muito precisa:

TEXTO: "${text}"${contextInfo}

Determine:
1. Inten√ß√£o prim√°ria: question, command, statement, exclamation, ou request
2. Confian√ßa na an√°lise (0-1)
3. Subtipo espec√≠fico da inten√ß√£o
4. Se requer resposta (true/false)
5. Prioridade: high, medium, ou low
6. Racioc√≠nio da an√°lise
7. A√ß√µes sugeridas

Responda em formato JSON:
{
  "primary": "question|command|statement|exclamation|request",
  "confidence": 0.9,
  "subtype": "what_question|general_statement|etc",
  "requiresResponse": true,
  "priority": "high|medium|low",
  "reasoning": "Explica√ß√£o do racioc√≠nio",
  "suggestedActions": ["a√ß√£o1", "a√ß√£o2"]
}`;

    const responseText = await callGLM4API(prompt, {
      temperature: 0.2,
      max_tokens: 400
    });

    try {
      const parsed = JSON.parse(responseText);
      return {
        primary: parsed.primary || 'statement',
        confidence: Math.max(0, Math.min(1, parsed.confidence || 0.7)),
        subtype: parsed.subtype || 'general',
        requiresResponse: Boolean(parsed.requiresResponse),
        priority: parsed.priority || 'medium',
        reasoning: parsed.reasoning || "An√°lise de inten√ß√£o conclu√≠da",
        suggestedActions: Array.isArray(parsed.suggestedActions) ? parsed.suggestedActions : []
      };
    } catch (parseError) {
      console.error('Erro ao parsear resposta de inten√ß√£o:', parseError);
      return {
        primary: 'statement',
        confidence: 0.3,
        subtype: 'general',
        requiresResponse: false,
        priority: 'low',
        reasoning: "Erro na an√°lise - resposta padr√£o",
        suggestedActions: []
      };
    }
  } catch (error) {
    console.error('Erro na detec√ß√£o de inten√ß√£o avan√ßada:', error);
    throw new Error('Falha na detec√ß√£o de inten√ß√£o');
  }
}

// Extra√ß√£o avan√ßada de entidades
export async function extractAdvancedEntities(text: string): Promise<{
  entities: Array<{
    text: string;
    type: string;
    confidence: number;
    startIndex: number;
    endIndex: number;
    description: string;
  }>;
  summary: string;
}> {
  try {
    const prompt = `Extraia todas as entidades importantes do seguinte texto:

TEXTO: "${text}"

Identifique e extraia:
- PESSOAS (nomes, t√≠tulos, profiss√µes)
- LUGARES (pa√≠ses, cidades, endere√ßos)
- ORGANIZA√á√ïES (empresas, institui√ß√µes)
- DATAS E HOR√ÅRIOS
- N√öMEROS E VALORES
- PRODUTOS E MARCAS
- EVENTOS

Para cada entidade, forne√ßa:
- Texto exato
- Tipo da entidade
- Confian√ßa (0-1)
- Posi√ß√£o no texto
- Breve descri√ß√£o

Responda em formato JSON:
{
  "entities": [
    {
      "text": "S√£o Paulo",
      "type": "LOCATION",
      "confidence": 0.95,
      "startIndex": 10,
      "endIndex": 19,
      "description": "Cidade no Brasil"
    }
  ],
  "summary": "Resumo das entidades encontradas"
}`;

    const responseText = await callGLM4API(prompt, {
      temperature: 0.1,
      max_tokens: 600
    });

    try {
      const parsed = JSON.parse(responseText);
      return {
        entities: Array.isArray(parsed.entities) ? parsed.entities.map((entity: any) => ({
          text: entity.text || '',
          type: entity.type || 'UNKNOWN',
          confidence: Math.max(0, Math.min(1, entity.confidence || 0.5)),
          startIndex: Math.max(0, entity.startIndex || 0),
          endIndex: Math.max(0, entity.endIndex || 0),
          description: entity.description || ''
        })) : [],
        summary: parsed.summary || "Extra√ß√£o de entidades conclu√≠da"
      };
    } catch (parseError) {
      console.error('Erro ao parsear resposta de entidades:', parseError);
      return {
        entities: [],
        summary: "Erro na extra√ß√£o - nenhuma entidade encontrada"
      };
    }
  } catch (error) {
    console.error('Erro na extra√ß√£o de entidades avan√ßada:', error);
    throw new Error('Falha na extra√ß√£o de entidades');
  }
}

// An√°lise contextual avan√ßada
export async function analyzeAdvancedContent(
  transcription: string,
  question: string,
  nlpAnalysis?: any,
  context?: string[],
  responseType: 'answer' | 'explanation' | 'clarification' | 'suggestion' = 'answer'
): Promise<AdvancedAnalysisResult> {
  try {
    const contextInfo = context && context.length > 0 
      ? `\n\nCONTEXTO DA CONVERSA ANTERIOR:\n${context.join('\n')}`
      : '';

    const nlpInfo = nlpAnalysis 
      ? `\n\nAN√ÅLISE NLP PR√âVIA:
- Sentimento: ${nlpAnalysis.sentiment?.polarity} (${Math.round((nlpAnalysis.sentiment?.intensity || 0) * 100)}%)
- Inten√ß√£o: ${nlpAnalysis.intent?.primary} - ${nlpAnalysis.intent?.subtype}
- Import√¢ncia: ${Math.round((nlpAnalysis.importance?.overall || 0) * 100)}%
- Entidades: ${nlpAnalysis.entities?.map((e: any) => e.text).join(', ') || 'Nenhuma'}
- T√≥picos: ${nlpAnalysis.topics?.map((t: any) => t.topic).join(', ') || 'Nenhum'}`
      : '';

    let promptInstruction = '';
    switch (responseType) {
      case 'explanation':
        promptInstruction = 'Forne√ßa uma explica√ß√£o detalhada e educativa.';
        break;
      case 'clarification':
        promptInstruction = 'Pe√ßa esclarecimentos ou forne√ßa uma resposta breve.';
        break;
      case 'suggestion':
        promptInstruction = 'Ofere√ßa sugest√µes pr√°ticas e √∫teis.';
        break;
      default:
        promptInstruction = 'Forne√ßa uma resposta direta e precisa.';
    }

    const prompt = `Voc√™ √© uma IA especialista em an√°lise inteligente de texto. ${promptInstruction}

TRANSCRI√á√ÉO: "${transcription}"

PERGUNTA/SOLICITA√á√ÉO: "${question}"${contextInfo}${nlpInfo}

Com base na an√°lise completa, forne√ßa uma resposta estruturada em JSON:
{
  "answer": "Resposta principal detalhada",
  "confidence": 0.9,
  "relatedTopics": ["t√≥pico1", "t√≥pico2", "t√≥pico3"],
  "reasoning": "Explica√ß√£o do racioc√≠nio usado",
  "additionalInsights": ["insight1", "insight2"],
  "contextAware": true
}

Seja inteligente, contextual e √∫til. Use toda a informa√ß√£o dispon√≠vel para dar a melhor resposta poss√≠vel.`;

    const responseText = await callGLM4API(prompt, {
      temperature: 0.4,
      max_tokens: 800
    });

    try {
      const parsed = JSON.parse(responseText);
      return {
        answer: parsed.answer || "N√£o foi poss√≠vel gerar uma resposta adequada.",
        confidence: Math.max(0, Math.min(1, parsed.confidence || 0.7)),
        relatedTopics: Array.isArray(parsed.relatedTopics) ? parsed.relatedTopics : [],
        responseType,
        contextAware: Boolean(parsed.contextAware),
        reasoning: parsed.reasoning || "An√°lise contextual aplicada",
        additionalInsights: Array.isArray(parsed.additionalInsights) ? parsed.additionalInsights : []
      };
    } catch (parseError) {
      console.error('Erro ao parsear resposta de an√°lise avan√ßada:', parseError);
      return {
        answer: responseText || "N√£o foi poss√≠vel processar a solicita√ß√£o.",
        confidence: 0.6,
        relatedTopics: ['an√°lise', 'transcri√ß√£o'],
        responseType,
        contextAware: false,
        reasoning: "Resposta direta sem parse JSON",
        additionalInsights: []
      };
    }
  } catch (error) {
    console.error('Erro na an√°lise avan√ßada de conte√∫do:', error);
    throw new Error('Falha na an√°lise avan√ßada de conte√∫do');
  }
}

// Detec√ß√£o inteligente de t√≥picos
export async function extractAdvancedTopics(text: string): Promise<{
  topics: Array<{
    topic: string;
    relevance: number;
    category: string;
    keywords: string[];
    confidence: number;
  }>;
  mainTheme: string;
  summary: string;
}> {
  try {
    const prompt = `Analise o seguinte texto e extraia os t√≥picos principais:

TEXTO: "${text}"

Identifique:
1. T√≥picos principais e sua relev√¢ncia (0-1)
2. Categoria de cada t√≥pico
3. Palavras-chave relacionadas
4. Tema principal geral
5. Confian√ßa na detec√ß√£o

Responda em formato JSON:
{
  "topics": [
    {
      "topic": "Tecnologia",
      "relevance": 0.8,
      "category": "Tech",
      "keywords": ["software", "app", "sistema"],
      "confidence": 0.9
    }
  ],
  "mainTheme": "Tema principal do texto",
  "summary": "Resumo dos t√≥picos encontrados"
}`;

    const responseText = await callGLM4API(prompt, {
      temperature: 0.3,
      max_tokens: 500
    });

    try {
      const parsed = JSON.parse(responseText);
      return {
        topics: Array.isArray(parsed.topics) ? parsed.topics.map((topic: any) => ({
          topic: topic.topic || 'Desconhecido',
          relevance: Math.max(0, Math.min(1, topic.relevance || 0.5)),
          category: topic.category || 'Geral',
          keywords: Array.isArray(topic.keywords) ? topic.keywords : [],
          confidence: Math.max(0, Math.min(1, topic.confidence || 0.7))
        })) : [],
        mainTheme: parsed.mainTheme || "Tema n√£o identificado",
        summary: parsed.summary || "An√°lise de t√≥picos conclu√≠da"
      };
    } catch (parseError) {
      console.error('Erro ao parsear resposta de t√≥picos:', parseError);
      return {
        topics: [],
        mainTheme: "Erro na an√°lise",
        summary: "N√£o foi poss√≠vel extrair t√≥picos"
      };
    }
  } catch (error) {
    console.error('Erro na extra√ß√£o avan√ßada de t√≥picos:', error);
    throw new Error('Falha na extra√ß√£o de t√≥picos');
  }
}